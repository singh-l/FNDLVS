{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we start with the liar dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the dataset\n",
    "df_train = pd.read_csv('../../../datasets/liar_tweaked/trainvectordata.csv')\n",
    "df_test = pd.read_csv('../../../datasets/liar_tweaked/testvectordata.csv')\n",
    "df_valid = pd.read_csv('../../../datasets/liar_tweaked/validvectordata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_train['statement']\n",
    "X_test=df_test['statement']\n",
    "Y_train=df_train['label']\n",
    "Y_test=df_test['label']\n",
    "X_valid=df_valid['statement']\n",
    "Y_valid=df_valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.append(X_valid, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=Y_test.append(Y_valid, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "#make necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test=tfidf_vectorizer.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2551, 11915)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tfidf_test.todense().tolist()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = np.array(tfidf_train.todense().tolist())\n",
    "tfidf_test = np.array(tfidf_test.todense().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train.tolist())\n",
    "Y_test = np.array(Y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10229, 11915)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxa=tfidf_train\n",
    "xxb=tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train=xxa\n",
    "tfidf_test=xxb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 200)               9612800   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 9,613,001\n",
      "Trainable params: 9,613,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Creating model\n",
    "\n",
    "# ## expand train dimnesion: pass from 2d to 3d\n",
    "tfidf_train = np.expand_dims(tfidf_train, axis=1)\n",
    "tfidf_test = np.expand_dims(tfidf_test, axis=1)\n",
    "model=Sequential()\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=False), input_shape=(1, 11915)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10229 samples, validate on 2551 samples\n",
      "Epoch 1/20\n",
      "10229/10229 [==============================] - 55s 5ms/sample - loss: 0.6781 - accuracy: 0.5654 - val_loss: 0.6683 - val_accuracy: 0.5766\n",
      "Epoch 2/20\n",
      "10229/10229 [==============================] - 45s 4ms/sample - loss: 0.6080 - accuracy: 0.6859 - val_loss: 0.6598 - val_accuracy: 0.6068\n",
      "Epoch 3/20\n",
      "10229/10229 [==============================] - 52s 5ms/sample - loss: 0.5004 - accuracy: 0.7789 - val_loss: 0.7208 - val_accuracy: 0.5931\n",
      "Epoch 4/20\n",
      "10229/10229 [==============================] - 44s 4ms/sample - loss: 0.4063 - accuracy: 0.8239 - val_loss: 0.8145 - val_accuracy: 0.5900\n",
      "Epoch 5/20\n",
      "10229/10229 [==============================] - 52s 5ms/sample - loss: 0.3353 - accuracy: 0.8595 - val_loss: 0.9310 - val_accuracy: 0.5915\n",
      "Epoch 6/20\n",
      "10229/10229 [==============================] - 44s 4ms/sample - loss: 0.2834 - accuracy: 0.8829 - val_loss: 1.0510 - val_accuracy: 0.5837\n",
      "Epoch 7/20\n",
      "10229/10229 [==============================] - 53s 5ms/sample - loss: 0.2469 - accuracy: 0.8985 - val_loss: 1.1752 - val_accuracy: 0.5782\n",
      "Epoch 8/20\n",
      "10229/10229 [==============================] - 54s 5ms/sample - loss: 0.2164 - accuracy: 0.9106 - val_loss: 1.2927 - val_accuracy: 0.5688\n",
      "Epoch 9/20\n",
      "10229/10229 [==============================] - 67s 7ms/sample - loss: 0.1926 - accuracy: 0.9219 - val_loss: 1.4233 - val_accuracy: 0.5704\n",
      "Epoch 10/20\n",
      "10229/10229 [==============================] - 52s 5ms/sample - loss: 0.1756 - accuracy: 0.9311 - val_loss: 1.5408 - val_accuracy: 0.5672\n",
      "Epoch 11/20\n",
      " 1280/10229 [==>...........................] - ETA: 34s - loss: 0.1266 - accuracy: 0.9555"
     ]
    }
   ],
   "source": [
    "model.fit(tfidf_train,Y_train,validation_data=(tfidf_test,Y_test),epochs=20,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now the kaggle dataset\n",
    "df = pd.read_csv('../../../datasets/kaggle/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['title'] + ' ' + df['text']\n",
    "df=df[df['content']==df['content']]\n",
    "df=df[df['label']==df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../../datasets/kaggle/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../../datasets/kaggle/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['content']\n",
    "Y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.reset_index()\n",
    "Y_test=Y_test.reset_index()\n",
    "X_train=X_train.reset_index()\n",
    "Y_train=Y_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=Y_test['label']\n",
    "X_test=X_test['content']\n",
    "X_train=X_train['content']\n",
    "Y_train=Y_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test=tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train=tfidf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train.tolist())\n",
    "Y_test = np.array(Y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 200)               125762400 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 125,762,601\n",
      "Trainable params: 125,762,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Creating model\n",
    "\n",
    "# ## expand train dimnesion: pass from 2d to 3d\n",
    "tfidf_train = np.expand_dims(tfidf_train, axis=1)\n",
    "tfidf_test = np.expand_dims(tfidf_test, axis=1)\n",
    "model=Sequential()\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=False), input_shape=(1, 157102)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15152 samples, validate on 5051 samples\n",
      "Epoch 1/20\n",
      "15152/15152 [==============================] - 985s 65ms/sample - loss: 0.3580 - accuracy: 0.8799 - val_loss: 0.1471 - val_accuracy: 0.9511\n",
      "Epoch 2/20\n",
      "15152/15152 [==============================] - 970s 64ms/sample - loss: 0.0628 - accuracy: 0.9850 - val_loss: 0.0970 - val_accuracy: 0.9657\n",
      "Epoch 3/20\n",
      "15152/15152 [==============================] - 932s 61ms/sample - loss: 0.0139 - accuracy: 0.9988 - val_loss: 0.0900 - val_accuracy: 0.9667\n",
      "Epoch 4/20\n",
      "15152/15152 [==============================] - 943s 62ms/sample - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.0893 - val_accuracy: 0.9669\n",
      "Epoch 5/20\n",
      "15152/15152 [==============================] - 940s 62ms/sample - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0908 - val_accuracy: 0.9673\n",
      "Epoch 6/20\n",
      "15152/15152 [==============================] - 1005s 66ms/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9677\n",
      "Epoch 7/20\n",
      "15152/15152 [==============================] - 1002s 66ms/sample - loss: 8.7429e-04 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9681\n",
      "Epoch 8/20\n",
      "15152/15152 [==============================] - 931s 61ms/sample - loss: 6.2253e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9675\n",
      "Epoch 9/20\n",
      " 1024/15152 [=>............................] - ETA: 12:58 - loss: 4.6033e-04 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "model.fit(tfidf_train,Y_train,validation_data=(tfidf_test,Y_test),epochs=20,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
